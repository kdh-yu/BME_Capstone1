{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor, SAM2Base\n",
    "\n",
    "predictor = SAM2ImagePredictor.from_pretrained(\"facebook/sam2-hiera-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare SAM 2\n",
    "model = predictor.model.cuda()\n",
    "\n",
    "image_encoder = model.image_encoder\n",
    "memory_encoder = model.memory_encoder\n",
    "memory_attention = model.memory_attention\n",
    "image_decoder = model.sam_mask_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examaple: Use 3 Images as Memory\n",
    "from PIL import Image\n",
    "memory_image_1 = Image.open('/home/kdh/code/BME_Capstone1/FAISS/A00028185_axial_107.png')\n",
    "memory_label_1 = Image.open('/home/kdh/code/BME_Capstone1/FAISS/A00028185_axial_107_mask.png')\n",
    "\n",
    "memory_image_2 = Image.open('/home/kdh/code/BME_Capstone1/FAISS/A00028185_axial_108.png')\n",
    "memory_label_2 = Image.open('/home/kdh/code/BME_Capstone1/FAISS/A00028185_axial_108_mask.png')\n",
    "\n",
    "memory_image_3 = Image.open('/home/kdh/code/BME_Capstone1/FAISS/A00028185_axial_109.png')\n",
    "memory_label_3 = Image.open('/home/kdh/code/BME_Capstone1/FAISS/A00028185_axial_109_mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing_sam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 192])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem1 = preprocessing_sam2(memory_image_1).cuda()\n",
    "mem1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgfeat = image_encoder(mem1.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ImageEncoder.forward of ImageEncoder(\n",
       "  (trunk): Hiera(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 144, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x MultiScaleBlock(\n",
       "        (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiScaleAttention(\n",
       "          (qkv): Linear(in_features=144, out_features=432, bias=True)\n",
       "          (proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=144, out_features=576, bias=True)\n",
       "            (1): Linear(in_features=576, out_features=144, bias=True)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (2): MultiScaleBlock(\n",
       "        (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "        (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        (attn): MultiScaleAttention(\n",
       "          (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (qkv): Linear(in_features=144, out_features=864, bias=True)\n",
       "          (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "            (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "        (proj): Linear(in_features=144, out_features=288, bias=True)\n",
       "      )\n",
       "      (3-7): 5 x MultiScaleBlock(\n",
       "        (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiScaleAttention(\n",
       "          (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
       "          (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "            (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (8): MultiScaleBlock(\n",
       "        (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "        (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        (attn): MultiScaleAttention(\n",
       "          (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (qkv): Linear(in_features=288, out_features=1728, bias=True)\n",
       "          (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "            (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "        (proj): Linear(in_features=288, out_features=576, bias=True)\n",
       "      )\n",
       "      (9-43): 35 x MultiScaleBlock(\n",
       "        (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiScaleAttention(\n",
       "          (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "          (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "            (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (44): MultiScaleBlock(\n",
       "        (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "        (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        (attn): MultiScaleAttention(\n",
       "          (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (qkv): Linear(in_features=576, out_features=3456, bias=True)\n",
       "          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "            (1): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "        (proj): Linear(in_features=576, out_features=1152, bias=True)\n",
       "      )\n",
       "      (45-47): 3 x MultiScaleBlock(\n",
       "        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MultiScaleAttention(\n",
       "          (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "          (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "            (1): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): FpnNeck(\n",
       "    (position_encoding): PositionEmbeddingSine()\n",
       "    (convs): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (conv): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (conv): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (conv): Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_encoder.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vision_features', 'vision_pos_enc', 'backbone_fpn'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgfeat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 16, 12])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgfeat['vision_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vision_features', 'vision_pos_enc', 'backbone_fpn'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem1feat = image_encoder(mem1.unsqueeze(0))\n",
    "mem1feat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mem1_mask = np.array(memory_label_1)\n",
    "mask_for_mem = torch.Tensor(np.where(mem1_mask>0, 1, 0)).unsqueeze(0).cuda()\n",
    "\n",
    "pix_feat = mem1feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "membank = memory_encoder(pix_feat['vision_features'], mask_for_mem, skip_mask_sigmoid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vision_features': tensor([[[[-1.4846e+00, -2.4006e+00, -2.0437e+00,  ..., -1.5841e-03,\n",
       "            -1.5754e+00, -2.3761e+00],\n",
       "           [-3.4426e-01, -3.2450e-03, -7.3652e-01,  ..., -4.0971e-01,\n",
       "             1.4022e-01, -6.6891e-03],\n",
       "           [-3.5967e+00, -3.7593e-01, -7.0714e-01,  ...,  7.6252e-01,\n",
       "             2.4212e-01, -1.2130e+00],\n",
       "           ...,\n",
       "           [-4.6076e-01,  5.3511e-02, -1.6299e+00,  ...,  9.2657e-02,\n",
       "             2.5566e-01,  2.7983e-01],\n",
       "           [-5.8862e-01,  4.1013e-02, -9.6927e-01,  ...,  8.9323e-02,\n",
       "            -6.0268e-01, -1.4948e+00],\n",
       "           [-8.9012e-01, -1.2158e+00, -9.3918e-01,  ...,  3.5316e-01,\n",
       "            -1.1954e+00, -1.5261e+00]],\n",
       " \n",
       "          [[-5.8099e-01, -9.7041e-01, -3.2968e-01,  ...,  1.0022e-01,\n",
       "             6.5936e-02, -5.1423e-01],\n",
       "           [ 1.5392e-01, -7.1067e-02, -9.9963e-01,  ..., -1.2612e+00,\n",
       "             6.6722e-02,  6.1804e-01],\n",
       "           [ 4.4484e-01, -7.6338e-02, -1.5921e+00,  ..., -1.0166e+00,\n",
       "             6.4852e-02,  1.1840e-01],\n",
       "           ...,\n",
       "           [ 3.5343e-01,  9.2199e-01, -1.8223e+00,  ...,  7.6890e-02,\n",
       "             1.3068e-02,  4.8722e-01],\n",
       "           [ 3.2158e-01,  2.5266e-01,  9.1107e-01,  ..., -6.6862e-02,\n",
       "             1.7434e-01,  1.9680e-01],\n",
       "           [-4.8625e-01, -6.8332e-01, -5.7881e-01,  ..., -3.6406e-01,\n",
       "            -6.4157e-01, -2.6662e-01]],\n",
       " \n",
       "          [[-3.7904e-01,  9.2147e-01,  8.5372e-01,  ...,  8.5811e-02,\n",
       "             9.1245e-01,  3.3020e-01],\n",
       "           [-8.1855e-03, -2.2384e-01, -1.2081e+00,  ..., -1.5697e+00,\n",
       "            -1.1219e+00, -3.4294e-01],\n",
       "           [-4.0430e-01,  2.7709e-01,  2.0946e-01,  ...,  1.1920e-02,\n",
       "            -2.4522e-01, -3.7090e-01],\n",
       "           ...,\n",
       "           [-3.0060e-01,  5.7650e-01, -6.3303e-01,  ...,  3.8116e-02,\n",
       "             1.1559e+00,  2.6247e-01],\n",
       "           [-4.3457e-01,  9.9743e-01, -1.4905e-01,  ...,  7.6229e-01,\n",
       "             1.0606e+00,  4.2480e-01],\n",
       "           [-3.6574e-01,  5.7167e-02,  6.5622e-01,  ...,  3.9023e-01,\n",
       "             5.8027e-01, -9.5237e-05]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.0849e-01, -9.2238e-02,  2.1131e+00,  ...,  2.9183e+00,\n",
       "             1.6365e+00,  3.5443e-01],\n",
       "           [ 2.0406e+00, -4.5233e-01,  2.2447e+00,  ...,  3.5146e+00,\n",
       "             2.1248e+00,  3.2962e-01],\n",
       "           [ 1.3556e+00,  1.5981e+00,  1.5413e+00,  ...,  2.1807e+00,\n",
       "             1.6246e+00,  2.1645e+00],\n",
       "           ...,\n",
       "           [-1.0304e+00, -5.7097e-01,  8.4839e-01,  ..., -5.0231e-02,\n",
       "            -2.1243e+00, -1.5552e+00],\n",
       "           [ 1.4420e+00,  4.2087e-01, -4.3311e-01,  ..., -1.2880e+00,\n",
       "            -5.7506e-01,  1.1883e+00],\n",
       "           [ 1.6268e+00,  3.8944e-01, -8.6611e-01,  ..., -1.8960e+00,\n",
       "             1.2267e-01,  9.1821e-01]],\n",
       " \n",
       "          [[-2.8199e-01, -6.2668e-01,  1.5816e-01,  ..., -1.3422e+00,\n",
       "            -6.5094e-01, -1.9686e+00],\n",
       "           [-5.9865e-01, -8.3878e-02,  1.8287e+00,  ...,  1.0706e+00,\n",
       "            -2.6981e-02, -9.6124e-01],\n",
       "           [ 1.3905e+00, -3.4394e-01,  2.4695e+00,  ...,  2.0672e+00,\n",
       "             4.3734e-01, -4.7953e-01],\n",
       "           ...,\n",
       "           [-5.9010e-02, -5.9201e-01, -1.1557e+00,  ..., -2.9779e+00,\n",
       "             5.2462e-02, -3.7077e-01],\n",
       "           [ 1.8688e-01, -5.1378e-01, -7.7344e-02,  ..., -1.1470e+00,\n",
       "            -8.0391e-01, -1.3707e+00],\n",
       "           [-1.1101e+00, -4.1988e-01,  4.0866e-01,  ..., -1.2638e-01,\n",
       "            -4.0125e-01, -1.3609e+00]],\n",
       " \n",
       "          [[ 6.5113e-01,  4.6940e-01, -1.4222e-01,  ..., -3.7575e-01,\n",
       "             1.3522e+00, -3.0732e-01],\n",
       "           [ 5.4426e-01,  7.7304e-02,  5.1252e-01,  ..., -4.2119e-01,\n",
       "            -1.4963e-01, -7.2524e-01],\n",
       "           [ 6.6653e-01,  1.1554e+00,  1.7024e+00,  ...,  7.8279e-01,\n",
       "             6.5733e-01, -1.4298e-01],\n",
       "           ...,\n",
       "           [ 3.4301e-01,  1.4940e+00,  7.9483e-01,  ...,  8.9644e-01,\n",
       "            -1.1493e+00, -9.2644e-01],\n",
       "           [-4.0589e-01,  1.1307e+00,  2.0130e+00,  ..., -7.3582e-01,\n",
       "            -8.0799e-01, -2.2546e-01],\n",
       "           [-2.3901e-01,  4.2529e-01,  8.6292e-01,  ..., -4.8882e-01,\n",
       "            -3.5877e-01, -5.7279e-01]]]], device='cuda:0',\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " 'vision_pos_enc': [tensor([[[[ 3.8268e-01,  3.8268e-01,  3.8268e-01,  ...,  3.8268e-01,\n",
       "              3.8268e-01,  3.8268e-01],\n",
       "            [ 7.0711e-01,  7.0711e-01,  7.0711e-01,  ...,  7.0711e-01,\n",
       "              7.0711e-01,  7.0711e-01],\n",
       "            [ 9.2388e-01,  9.2388e-01,  9.2388e-01,  ...,  9.2388e-01,\n",
       "              9.2388e-01,  9.2388e-01],\n",
       "            ...,\n",
       "            [-7.0711e-01, -7.0711e-01, -7.0711e-01,  ..., -7.0711e-01,\n",
       "             -7.0711e-01, -7.0711e-01],\n",
       "            [-3.8268e-01, -3.8268e-01, -3.8268e-01,  ..., -3.8268e-01,\n",
       "             -3.8268e-01, -3.8268e-01],\n",
       "            [-7.7883e-07, -7.7883e-07, -7.7883e-07,  ..., -7.7883e-07,\n",
       "             -7.7883e-07, -7.7883e-07]],\n",
       "  \n",
       "           [[ 9.2388e-01,  9.2388e-01,  9.2388e-01,  ...,  9.2388e-01,\n",
       "              9.2388e-01,  9.2388e-01],\n",
       "            [ 7.0711e-01,  7.0711e-01,  7.0711e-01,  ...,  7.0711e-01,\n",
       "              7.0711e-01,  7.0711e-01],\n",
       "            [ 3.8268e-01,  3.8268e-01,  3.8268e-01,  ...,  3.8268e-01,\n",
       "              3.8268e-01,  3.8268e-01],\n",
       "            ...,\n",
       "            [ 7.0711e-01,  7.0711e-01,  7.0711e-01,  ...,  7.0711e-01,\n",
       "              7.0711e-01,  7.0711e-01],\n",
       "            [ 9.2388e-01,  9.2388e-01,  9.2388e-01,  ...,  9.2388e-01,\n",
       "              9.2388e-01,  9.2388e-01],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00]],\n",
       "  \n",
       "           [[ 2.1904e-01,  2.1904e-01,  2.1904e-01,  ...,  2.1904e-01,\n",
       "              2.1904e-01,  2.1904e-01],\n",
       "            [ 4.2744e-01,  4.2744e-01,  4.2744e-01,  ...,  4.2744e-01,\n",
       "              4.2744e-01,  4.2744e-01],\n",
       "            [ 6.1508e-01,  6.1508e-01,  6.1508e-01,  ...,  6.1508e-01,\n",
       "              6.1508e-01,  6.1508e-01],\n",
       "            ...,\n",
       "            [ 4.9939e-02,  4.9939e-02,  4.9939e-02,  ...,  4.9939e-02,\n",
       "              4.9939e-02,  4.9939e-02],\n",
       "            [-1.7004e-01, -1.7004e-01, -1.7004e-01,  ..., -1.7004e-01,\n",
       "             -1.7004e-01, -1.7004e-01],\n",
       "            [-3.8176e-01, -3.8176e-01, -3.8176e-01,  ..., -3.8176e-01,\n",
       "             -3.8176e-01, -3.8176e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            ...,\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00]],\n",
       "  \n",
       "           [[ 9.3110e-05,  1.8622e-04,  2.7933e-04,  ...,  9.3110e-04,\n",
       "              1.0242e-03,  1.1173e-03],\n",
       "            [ 9.3110e-05,  1.8622e-04,  2.7933e-04,  ...,  9.3110e-04,\n",
       "              1.0242e-03,  1.1173e-03],\n",
       "            [ 9.3110e-05,  1.8622e-04,  2.7933e-04,  ...,  9.3110e-04,\n",
       "              1.0242e-03,  1.1173e-03],\n",
       "            ...,\n",
       "            [ 9.3110e-05,  1.8622e-04,  2.7933e-04,  ...,  9.3110e-04,\n",
       "              1.0242e-03,  1.1173e-03],\n",
       "            [ 9.3110e-05,  1.8622e-04,  2.7933e-04,  ...,  9.3110e-04,\n",
       "              1.0242e-03,  1.1173e-03],\n",
       "            [ 9.3110e-05,  1.8622e-04,  2.7933e-04,  ...,  9.3110e-04,\n",
       "              1.0242e-03,  1.1173e-03]],\n",
       "  \n",
       "           [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            ...,\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00],\n",
       "            [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "              1.0000e+00,  1.0000e+00]]]], device='cuda:0')]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "membank#.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
